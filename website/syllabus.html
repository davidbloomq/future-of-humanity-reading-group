<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Syllabus — Future of Humanity Reading Group</title>
</head>
<body>
    <p><a href="index.html">Home</a> · <a href="meeting.html">Next Meeting</a></p>

    <h1>Syllabus</h1>
    <p><i>This syllabus is tentative and subject to change.</i></p>

    <h3>Week 1: Foundations <small>(confirmed)</small></h3>
    <ul>
        <li>Bostrom, "The Future of Humanity" (2007) — <a href="https://nickbostrom.com/papers/future">Link</a></li>
        <li>Bostrom, "The Vulnerable World Hypothesis" (2019) — <a href="https://nickbostrom.com/papers/vulnerable.pdf">PDF</a> · <a href="https://aeon.co/essays/none-of-our-technologies-has-managed-to-destroy-humanity-yet">Aeon summary</a></li>
        <li>Karnofsky, "The Most Important Century" (2021):
            <ul>
                <li><a href="https://www.cold-takes.com/most-important-century-series-roadmap/">Roadmap</a></li>
                <li><a href="https://www.cold-takes.com/all-possible-views-about-humanitys-future-are-wild/">All Possible Views About Humanity's Future Are Wild</a></li>
                <li><a href="https://www.cold-takes.com/the-duplicator/">The Duplicator</a></li>
                <li><a href="https://www.cold-takes.com/how-digital-people-could-change-the-world/">Digital People Could Change the World</a></li>
                <li><a href="https://www.cold-takes.com/why-ai-alignment-could-be-hard-with-modern-deep-learning/">Why AI Alignment Could Be Hard</a></li>
                <li><a href="https://www.cold-takes.com/making-the-best-of-the-most-important-century/">How to Make the Best of the Most Important Century</a></li>
            </ul>
        </li>
    </ul>

    <h3>Week 2: Population Ethics, Longtermism &amp; Decision Under Uncertainty <small>(confirmed — <a href="meeting.html">next meeting</a>)</small></h3>
    <ul>
        <li>Bostrom, "Astronomical Waste" (2003) — <a href="https://nickbostrom.com/papers/astronomical-waste/">Link</a></li>
        <li>Greaves, "Population Axiology" (2017) — <a href="https://philpapers.org/archive/GREPA-6.pdf">PDF</a> (reading guide forthcoming)</li>
        <li>Greaves &amp; MacAskill, "The Case for Strong Longtermism" (2021) — <a href="https://globalprioritiesinstitute.org/hilary-greaves-william-macaskill-the-case-for-strong-longtermism-2/">GPI Working Paper</a></li>
        <li><i>Alternative to Greaves:</i> Parfit, <i>Reasons and Persons</i> (1984) Ch. 16–18 — covers the same material in a more expository (but still dense) style, while Greaves is more comprehensive but written in terse language aimed at academic philosophers</li>
        <li><i>Optional:</i> Mogensen, "Maximal Cluelessness" (2021) — <a href="https://www.globalprioritiesinstitute.org/wp-content/uploads/Andreas-Mogensen_Maximal-cluelessness.pdf">GPI Working Paper</a></li>
    </ul>

    <h3>Week 3: Long-Run Growth &amp; Technological Development</h3>
    <ul>
        <li>Kremer, "Population Growth and Technological Change: One Million B.C. to 1990" (1993) — <a href="https://faculty.econ.ucdavis.edu/faculty/gclark/210a/readings/kremer1993.pdf">PDF</a></li>
        <li>Jones, "The Facts of Economic Growth" (2016) — <a href="https://www.nber.org/system/files/working_papers/w21142/w21142.pdf">NBER Working Paper</a></li>
        <li>Hanson, <i>The Age of Em</i> (2016) Ch. 1–4</li>
        <li><i>Optional:</i> Romer, "Endogenous Technological Change" (1990)</li>
    </ul>

    <h3>Week 4: Artificial Intelligence &amp; Civilization</h3>
    <ul>
        <li>Drago &amp; Laine, "The Intelligence Curse" (2025) — <a href="https://intelligence-curse.ai/intelligence-curse.pdf">PDF</a></li>
        <li>Bostrom, "The Superintelligent Will" (2012) — <a href="https://nickbostrom.com/superintelligentwill.pdf">PDF</a></li>
        <li>Carlsmith, "Is Power-Seeking AI an Existential Risk?" (2022) — <a href="https://jc.gatspress.com/pdf/existential_risk_and_powerseeking_ai.pdf">PDF (summary)</a></li>
        <li><i>Optional:</i> Carlsmith, full version — <a href="https://arxiv.org/abs/2206.13353">arXiv</a></li>
    </ul>

    <h3>Week 5: Digital Minds</h3>
    <ul>
        <li>Block, "The Mind as the Software of the Brain" (1995) — <a href="https://www.nyu.edu/gsas/dept/philo/faculty/block/papers/msb.html">Link</a></li>
        <li>Egan, "Learning to Be Me" (1990) — <a href="https://gwern.net/doc/fiction/science-fiction/1995-egan.pdf">PDF</a></li>
        <li>Schwitzgebel &amp; Garza, "A Defense of the Rights of Artificial Intelligences" (2015) — <a href="https://www.faculty.ucr.edu/~eschwitz/SchwitzPapers/AIRights-150915.pdf">PDF</a></li>
        <li><i>Optional:</i> Chalmers, "Facing Up to the Problem of Consciousness" (1995) — <a href="https://consc.net/papers/facing.pdf">PDF</a></li>
    </ul>

    <h3>Week 6: Governance, Institutions &amp; Long-Run Coherence</h3>
    <ul>
        <li>Dafoe, "On Technological Determinism" (2015) — <a href="https://www.allandafoe.com/technologicaldeterminism">Link</a></li>
        <li>Ord, <i>The Precipice</i> (2020), Ch. 6 &amp; Ch. 8 — <a href="https://theprecipice.com/">Book site</a></li>
        <li>Scott, <i>Seeing Like a State</i> (1998), Introduction (~20 pages) — <a href="https://theanarchistlibrary.org/library/james-c-scott-seeing-like-a-state">Full text</a></li>
        <li><i>Optional:</i> Ostrom, <i>Governing the Commons</i> (1990), Ch. 1–2 — <a href="https://www.burmalibrary.org/docs20/Ostrom-1990-governing_the_commons.pdf">PDF</a></li>
        <li><i>Optional:</i> Posner, <i>Catastrophe: Risk and Response</i> (2004), selected chapters</li>
    </ul>

    <h3>Week 7: Coordination, Coherence &amp; the Dreamtime</h3>
    <ul>
        <li>Bostrom, "What is a Singleton?" (2006) — <a href="https://nickbostrom.com/fut/singleton">Link</a></li>
        <li>Hanson, "This is the Dream Time" (2009) — <a href="https://www.overcomingbias.com/p/this-is-the-dream-timehtml">Link</a> · <a href="https://www.overcomingbias.com/p/dreamtime-gameshtml">Dreamtime Games</a></li>
        <li>Huntington, <i>Political Order in Changing Societies</i> (1968) pp. 8–24</li>
        <li><i>Optional:</i> Schelling, <i>The Strategy of Conflict</i> (1960) Ch. 2 &amp; 5</li>
    </ul>

    <h3>Week 8: The Fermi Paradox &amp; Cosmic-Scale Civilization</h3>
    <ul>
        <li>Hart, "Explanation for the Absence of Extraterrestrials on Earth" (1975) — <a href="https://adsabs.harvard.edu/full/1975QJRAS..16..128H">ADS Full Text</a></li>
        <li>Hanson, "The Great Filter" (1998) — <a href="https://mason.gmu.edu/~rhanson/greatfilter.html">Link</a></li>
        <li>Sandberg, Drexler &amp; Ord, "Dissolving the Fermi Paradox" (2018) — <a href="https://arxiv.org/abs/1806.02404">arXiv</a></li>
        <li>Armstrong &amp; Sandberg, "Eternity in Six Hours" (2013) — <a href="https://www.flightfromperfection.com/files/far_future/Sharpening%20the%20Fermi%20Paradox%20(Armstrong,2013).pdf">PDF</a></li>
        <li><i>Optional:</i> Carroll-Nellenback et al., "The Fermi Paradox and the Aurora Effect" (2019) — <a href="https://arxiv.org/abs/1902.04450">arXiv</a></li>
        <li><i>Optional:</i> Elga, "Self-Locating Belief and the Sleeping Beauty Problem" (2000) — <a href="https://www.princeton.edu/~adame/papers/sleeping/sleeping.pdf">PDF</a></li>
        <li><i>Optional:</i> Bostrom, <i>Anthropic Bias</i> (2002) Ch. 6 — <a href="https://anthropic-principle.com/q=book/chapter_6/">Link</a></li>
    </ul>

    <h3>Week 9: Utopia</h3>
    <ul>
        <li>Suits, <i>The Grasshopper: Games, Life and Utopia</i> (1978)</li>
        <li>Forethought Foundation, Better Futures Project — <a href="https://www.forethought.org/research/viatopia">Viatopia</a> · <a href="https://www.forethought.org/research/no-easy-eutopia">No Easy Eutopia</a> · <a href="https://www.forethought.org/research/introducing-better-futures">Introducing Better Futures</a></li>
        <li>Keynes, "Economic Possibilities for Our Grandchildren" (1930) — <a href="http://www.econ.yale.edu/smith/econ116a/keynes1.pdf">PDF</a></li>
        <li><i>Optional:</i> Ćirković, "Cosmological Forecast and Its Practical Significance" — <a href="https://www.jetpress.org/volume12/CosmologicalForecast.pdf">PDF</a></li>
    </ul>

</body>
</html>
